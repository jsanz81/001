{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covarianza\n",
    "\n",
    "Hemos hablado de la varianza (la desviación cuadrática promedio de la media). La covarianza es, como habrás adivinado, similar. Digamos que tenemos un vector de datos, $x^a$, que tiene $i$ puntos... entonces $x_i^a$ es el primer elemento del vector de datos, de la sección anterior tendríamos que:\n",
    "\n",
    "$$ Var_{a,a} = \\frac{1}{N} \\sum_{i=1}^N (x_i^a - \\mu^a)(x_i^a - \\mu^a), $$\n",
    "\n",
    "Esto debería parecerse a la última sección, excepto que he pegado $a$ en algunos lugares. Otra forma de decir esto es que esta es la covarianza del vector $x^a$ consigo mismo. Observe que hay dos conjuntos de corchetes, ambos usan el vector de datos $x^a$. La covarianza es lo que obtienes cuando cambias una de las letras. Como esto:\n",
    "\n",
    "$$ Var_{a,b} = \\frac{1}{N} \\sum_{i=1}^N (x_i^a - \\mu^a)(x_i^b - \\mu^b), $$\n",
    "\n",
    "¡Fácil! Todo lo que hemos hecho ahora es que un conjunto entre paréntesis itera sobre un vector de datos diferente. El objetivo es hacer esto para cada vector diferente que tengas para formar una matriz. Si tuviéramos solo dos vectores, nuestra matriz sería esta:\n",
    "\n",
    "$$ Cov = \\begin{pmatrix} Var_{a,a} & Var_{a,b} \\\\ Var_{b,a} & Var_{b,b} \\\\ \\end{pmatrix} $$\n",
    "\n",
    "Observe cómo esto es simétrico. $Var_{a,b} = Var_{b,a}$. Y las diagonales son solo la varianza de cada vector de datos. Las diagonales son la medida de la extensión conjunta entre los dos. Si el concepto aún no es perfecto, no se preocupe, los ejemplos lo aclararán todo.\n",
    "\n",
    "Podemos calcular la covarianza usando cualquiera `np.cov` ([documentación](https://docs.scipy.org/doc/numpy/reference/generated/numpy.cov.html)) or `pd.DataFrame.cov` ([documentación](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.cov.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"height_weight.csv\")[[\"height\", \"weight\"]]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covarianza = np.cov(dataset, rowvar=False)\n",
    "print(covarianza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covarianza = dataset.cov()\n",
    "print(covarianza)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlación\n",
    "La correlación y la covarianza se vinculan fácilmente. Si tomamos la matriz de covarianza 2D de arriba, que está escrita en términos de varianza, podemos reescribirla en términos de desviación estándar $\\sigma$, como $Var = \\sigma^2$.\n",
    "\n",
    "$$ Cov = \\begin{pmatrix} \\sigma^2_{a,a} & \\sigma^2_{a,b} \\\\ \\sigma^2_{b,a} & \\sigma^2_{b,b} \\ \\ \\end{pmatrix} $$\n",
    "\n",
    "Excelente. Y aquí está la matriz de correlación:\n",
    "\n",
    "$$ Corr = \\begin{pmatrix} \\sigma^2_{a,a}/\\sigma^2_{a,a} & \\sigma^2_{a,b}/(\\sigma_{a,a}\\sigma_{ b,b}) \\\\ \\sigma^2_{b,a}/(\\sigma_{a,a}\\sigma_{b,b}) & \\sigma^2_{b,b}/\\sigma^2_{b ,b} \\\\ \\end{pmatrix} $$\n",
    "\n",
    "que es lo mismo que\n",
    "\n",
    "$$ Corr = \\begin{pmatrix} 1 & \\rho_{a,b} \\\\ \\rho_{b,a} & 1 \\\\ \\end{pmatrix}, $$\n",
    "\n",
    "donde $\\rho_{a,b} = \\sigma^2_{a,b}/(\\sigma_{a,a}\\sigma_{b,b})$. Otra forma de pensar en esto es que\n",
    "\n",
    "$$ Corr_{a,b} = \\frac{Cov_{a,b}}{\\sigma_a \\sigma_b} $$\n",
    "\n",
    "Es la variabilidad conjunta normalizada por la variabilidad de cada variable independiente.\n",
    "\n",
    "Pero esto *todavía es demasiado matemático para mí*. Volvamos al código. Podemos calcular una matriz de correlación usando `np.corrcoef` ([documentación](https://docs.scipy.org/doc/numpy/reference/generated/numpy.corrcoef.html)) o `pd.DataFrame.corr` ([documentación](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = np.corrcoef(dataset.T)\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = dataset.corr()\n",
    "corr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Entonces, qué significa esto? En términos tan simples como puedo decirlo, el hecho de que tengamos un número positivo para la correlación peso-altura significa que, *en promedio*, una persona más alta probablemente pesa más (que una persona más baja). Una persona más baja, *en promedio* probablemente pesa menos que una persona alta.\n",
    "\n",
    "Si el número fuera negativo, significaría lo contrario: una persona alta normalmente pesaría menos que una persona baja. Uno es lo más lejos que puedes llegar, y si nuestros $0.468$ fueran $1$, significaría que una persona alta *siempre* pesaría más que una persona baja. Cuanto mayor sea el número (en términos absolutos), más probable es que encuentre esa correlación.\n",
    "\n",
    "Aquí hay algunos otros ejemplos:\n",
    "\n",
    "* **Edad vs número de embarazos**: Correlación positiva\n",
    "* **Temperatura en Celcius vs Temperatura en Kelvin**: Correlación positiva total ($1.0$)\n",
    "* **Cantidad de cigarrillos fumados vs Esperanza de vida**: Correlación negativa\n",
    "* **Altura vs Confort en asientos de avión**: Correlación negativa\n",
    "* **Número de unidades compradas frente al costo de la unidad individual**: ¡Con suerte, una correlación negativa!\n",
    "\n",
    "Tome dos cosas y pregúntese, si una sube, ¿espero que la otra baje, baje o no cambie?\n",
    "\n",
    "Eso es correlación. Y ahora puedes cuantificarlo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
