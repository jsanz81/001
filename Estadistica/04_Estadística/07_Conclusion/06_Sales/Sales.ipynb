{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ventas con Incertidumbre\n",
    "\n",
    "Usando datos desde [Kaggle, Rossman stores](https://www.kaggle.com/c/rossmann-store-sales/data).\n",
    "\n",
    "Nuestro objetivo en este ejemplo es estimar las ventas promedio en función del día de la semana, con un análisis de incertidumbre derivado de dos formas: analíticamente y mediante realización aleatoria. Este ejemplo no pretende ser lo que le gustaría hacer en este escenario para responder a una pregunta simple, sino una buena práctica sobre cómo simular RV para estimar la incertidumbre, la pérdida de información que se produce si realiza aproximaciones analíticas, pero por qué pueden ser útiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, lognorm\n",
    "df = pd.read_csv(\"sales.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.loc[(df.Open == 1), [\"Store\", \"DayOfWeek\", \"Sales\", \"Customers\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(df2.iloc[::100, :], figsize=(6, 6));"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He aquí una forma muy breve de hacer las cosas. Agregue y regrese con una suposición gaussiana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.groupby(\"DayOfWeek\").agg({\"Sales\": [\"mean\", \"std\"]})\n",
    "df3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero esto no es tan educativo. En su lugar, tracemos una distribución, una por día de la semana, para la venta promedio de cualquier cliente dado (sobre todas las tiendas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for day, frame in df2.groupby(\"DayOfWeek\"):\n",
    "    plt.hist(frame.Sales / frame.Customers, bins=50, label=day, histtype='step', density=True)\n",
    "plt.legend()\n",
    "plt.xlabel(\"$ Spent\")\n",
    "plt.ylabel(\"P($)\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Parece un buen ajuste para un normal para mí! (No mires el domingo, que duele). Echemos un vistazo a la relación entre las medias y las desviaciones estándar de cada día."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "for day, frame in df2.groupby(\"DayOfWeek\"):\n",
    "    data = frame.Sales / frame.Customers\n",
    "    mean, std = data.mean(), data.std()\n",
    "    res[day] = {\"Gasto\": (mean, std)}\n",
    "    plt.scatter([mean], [std], label=day, s=30)\n",
    "plt.legend();\n",
    "plt.xlabel(\"Media Gasto\")\n",
    "plt.ylabel(\"Dispersión Gasto\")\n",
    "print(res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vaya, ¿qué está pasando el domingo? ¡No es un día rentable en absoluto! La relación casi lineal que vemos a la derecha sería coherente con la escala de la varianza en función del gasto. Es decir, si normalizamos el diferencial en términos de gasto, podría aplanarse. Solo como un lado interesante, en realidad no necesitamos usar esa información en los datos, ¡pero lo tenemos por si acaso!\n",
    "\n",
    "Por ejemplo, si tuviéramos que usar esta información de datos, solo necesitaríamos la cantidad de clientes y el gasto medio (dos vectores de datos) en lugar de la cantidad de clientes, el gasto medio y la distribución del gasto. Porque podemos utilizar las relaciones existentes para predecir eso. Pero dado que nuestros datos se han extendido, ¡también podríamos usar eso!\n",
    "\n",
    "Ahora, tenemos nuestra aproximación normal al gasto por cliente. Ahora necesitamos cuantificar el número de clientes en función del día. Visualicemos de nuevo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day, frame in df2.groupby(\"DayOfWeek\"):\n",
    "    plt.hist(frame.Customers, bins=100, histtype=\"step\", label=day, density=True)\n",
    "plt.legend();\n",
    "plt.xlabel(\"# Clientes\")\n",
    "plt.ylabel(\"P(Num)\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maldito domingo, deja de arruinar todo. En este punto, estaría investigando el domingo más si solo tuviera los datos. ¿Diferencias de horario de apertura? ¿Descuentos el domingo? ¿Solo algunas tiendas abren los domingos en áreas más pobladas o áreas en áreas socioeconómicas más altas? Nos gustaría encontrar datos complementarios para profundizar en esto, lo que puede hacer fácilmente si está trabajando en un entorno empresarial, pero no puede hacerlo si está utilizando datos antiguos de código abierto.\n",
    "\n",
    "Ahora, número de clientes, solo número positivo, contando valores reales... ¡suena como una buena aplicación para un registro normal para mí!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(10,6), nrows=2, ncols=4, sharey=True, sharex=True)\n",
    "fig.subplots_adjust(wspace=0)\n",
    "\n",
    "for ax, (day, frame) in zip(axes.flatten(), df2.groupby(\"DayOfWeek\")):\n",
    "    params = lognorm.fit(frame.Customers, scale=1000)\n",
    "    ax.hist(frame.Customers, bins=100, density=True, histtype=\"step\")\n",
    "    xs = np.linspace(frame.Customers.min(), frame.Customers.max(), 100)\n",
    "    ax.plot(xs, lognorm.pdf(xs, *params))\n",
    "    ax.set_title(day)\n",
    "    ax.set_xlim(0, 3000)\n",
    "    res[day][\"cust\"] = list(params)\n",
    "    print(day, params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, con la excepción del domingo, realmente podríamos modelar *todas* estas distancias con una media de 0, un parámetro de forma de alrededor de 0,4 y una escala que varía ligeramente con cada día, generalmente alrededor de 700.\n",
    "\n",
    "De nuevo, esto va en la línea de encontrar la información que es importante en los datos. Si descartamos el domingo y usamos la información de datos anterior, ahora podemos decir que las ganancias diarias se pueden predecir usando solo dos números: la escala de la norma logarítmica que representa la cantidad de clientes y el valor medio del gasto de cada cliente. Inferiríamos cualquier otro valor.\n",
    "\n",
    "Comparemos esa inferencia de número reducido, con una inferencia completa, solo con el promedio con el que comenzamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.groupby(\"DayOfWeek\").agg({\"Sales\": [\"mean\", \"std\"], \"Customers\": [\"mean\", \"std\"]}).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si quisiéramos dibujar valores simulados y ejecutarlos (en lugar de usar los datos reales)\n",
    "percentiles = 100 * norm.cdf([-1, 0, 1])\n",
    "n = 100000\n",
    "# para cada día, muestree # clientes y muestree su gasto\n",
    "for day, dic in res.items():\n",
    "    spend = norm(*dic[\"spend\"]).rvs(n)\n",
    "    custs = lognorm(*dic[\"cust\"]).rvs(n)\n",
    "    profit = custs * spend\n",
    "    vals = np.percentile(profit, percentiles)\n",
    "    diff = np.diff(vals)\n",
    "    print(f\"Día {day} tiene benificios {vals[1]:.2f}(+{diff[1]:.2f})(-{diff[0]:.2f})\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Tenga en cuenta que estas estimaciones son más bajas! El uso de este método es menos sensible a los valores atípicos que aumentan las ganancias, y obviamente hemos perdido algo de información en nuestras aproximaciones.\n",
    "\n",
    "Consideremos ahora el caso en que comprimimos los datos en solo dos números: número medio de clientes y gasto promedio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day, dic in res.items():\n",
    "    mean_spend = dic[\"spend\"][0]\n",
    "    num_cust = dic[\"cust\"][2]\n",
    "    \n",
    "    spend = norm(mean_spend, mean_spend*0.25).rvs(n)\n",
    "    custs = lognorm(0.4, 0, num_cust).rvs(n)\n",
    "    profit = custs * spend\n",
    "    vals = np.percentile(profit, percentiles)\n",
    "    diff = np.diff(vals)\n",
    "    print(f\"Día {day} tiene beneficios {vals[1]:.2f}(+{diff[1]:.2f})(-{diff[0]:.2f})\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así que puedes ver, aparte del domingo, esta es una aproximación bastante buena. Y si hace algo como esto, puede intentar responder más preguntas fácilmente. Imagine que ahora obtiene información de que en la semana anterior a las vacaciones la cantidad que la gente gasta se dispersa más. Por ejemplo, hay un aumento del 50 % en la dispersión del gasto y la gente también gasta en promedio un dólar más. ¿Cómo afectaría eso a las ganancias?\n",
    "\n",
    "Usando la forma original, no es obvio cómo escribiríamos una estimación de una línea. Pero es fácil con nuestras aproximaciones: simplemente modifique las distribuciones de las que estamos dibujando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day, dic in res.items():\n",
    "    mean_spend = dic[\"spend\"][0]\n",
    "    num_cust = dic[\"cust\"][2]\n",
    "    \n",
    "    spend = norm(mean_spend+1, mean_spend*0.25*1.5).rvs(n)\n",
    "    custs = lognorm(0.4, 0, num_cust).rvs(n)\n",
    "    profit = custs * spend\n",
    "    vals = np.percentile(profit, percentiles)\n",
    "    diff = np.diff(vals)\n",
    "    print(f\"Día {day} tiene beneficios {vals[1]:.2f}(+{diff[1]:.2f})(-{diff[0]:.2f})\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenga en cuenta que en este ejemplo no hay ninguna razón real por la que haríamos todo este esfuerzo para caracterizar nuestras distribuciones solo para tomar muestras de ellas nuevamente. Simplemente usaríamos los datos reales; tenemos suficientes muestras para hacerlo. O una muestra del PDF empírico si *realmente* queríamos muestrear. Este ejercicio simplemente pretende mostrarle cómo *puede* usar el muestreo de números aleatorios para estimar la incertidumbre. También significa que podemos responder preguntas más flexibles: el método original de una línea solo se adapta a los escenarios exactamente como los describen los datos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
